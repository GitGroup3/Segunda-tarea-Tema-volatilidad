{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing the necessary package \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "# Importamos el paquete yfinance, que nos permite descargar datos financieros de Yahoo Finance.\n",
    "import yfinance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el módulo warningspara poder gestionar las advertencias que se generan durante la ejecución del programa.\n",
    "import warnings \n",
    "\n",
    "# warnings.filterwarnings(\"ignore\"): Esta línea desactiva temporalmente la generación de advertencias. En otras palabras, cualquier advertencia que pueda haber sido generada durante la ejecución del programa no se mostrará en la salida.\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 downloaded\n"
     ]
    }
   ],
   "source": [
    "# Using the .download() method to get our data\n",
    "# Descargamos datos financieros utilizando el módulo yfinance. Los parámetros utilizados en la función downloadson:\n",
    "raw_data = yfinance.download (tickers = \"^GSPC ^FTSE ^N225 ^GDAXI\", start = \"1994-01-07\", end = \"2019-09-27\", interval = \"1d\", group_by = 'ticker', auto_adjust = True, threads = True)\n",
    "\n",
    "# tickers -> The time series we are interested in - (in our case, these are the S&P, FTSE, NIKKEI and DAX)\n",
    "# start -> The starting date of our data set\n",
    "# end -> The ending date of our data set (at the time of upload, this is the current date)\n",
    "# interval -> The distance in time between two recorded observations. Since we're using daily closing prices, we set it equal to \"1d\", which indicates 1 day. \n",
    "# group_by -> The way we want to group the scraped data. Usually we want it to be \"ticker\", so that we have all the information about a time series in 1 variable.\n",
    "# auto_adjust -> Automatically adjust the closing prices for each period. \n",
    "# threads - > Whether to use threads for mass downloading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a back up copy in case we remove/alter elements of the data by mistake\n",
    "df_comp = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new columns to the data set\n",
    "df_comp['spx'] = df_comp['^GSPC'].Close\n",
    "df_comp['dax'] = df_comp['^GDAXI'].Close\n",
    "df_comp['ftse'] = df_comp['^FTSE'].Close\n",
    "df_comp['nikkei'] = df_comp['^N225'].Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comp = df_comp.iloc[1:] # Removing the first elements, since we always start 1 period before the first, due to time zone differences of closing prices\n",
    "del df_comp['^N225']  # Removing the original tickers of the data set\n",
    "del df_comp['^GSPC']\n",
    "del df_comp['^GDAXI']\n",
    "del df_comp['^FTSE']\n",
    "# Eliminamos el primer elementodf_comp. Esto se hace utilizando la función iloc\n",
    "df_comp=df_comp.asfreq('b') # Setting the frequency of the data\n",
    "df_comp=df_comp.fillna(method='ffill') # Filling any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               spx      dax    ftse    nikkei\n",
      "                                             \n",
      "Date                                         \n",
      "1994-01-07  469.90  2224.95  3446.0  18124.01\n",
      "1994-01-10  475.27  2225.00  3440.6  18443.44\n",
      "1994-01-11  474.13  2228.10  3413.8  18485.25\n",
      "1994-01-12  474.17  2182.06  3372.0  18793.88\n",
      "1994-01-13  472.47  2142.37  3360.0  18577.26\n",
      "                spx       dax    ftse    nikkei\n",
      "                                               \n",
      "Date                                           \n",
      "2019-09-20  2992.07  12468.01  7344.9  22079.09\n",
      "2019-09-23  2991.78  12342.33  7326.1  22079.09\n",
      "2019-09-24  2966.60  12307.15  7291.4  22098.84\n",
      "2019-09-25  2984.87  12234.18  7290.0  22020.15\n",
      "2019-09-26  2977.62  12288.54  7351.1  22048.24\n"
     ]
    }
   ],
   "source": [
    "print (df_comp.head()) # Displaying the first 5 elements to make sure the data was scraped correctly\n",
    "print (df_comp.tail()) # Making sure the last day we're including in the series are correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
